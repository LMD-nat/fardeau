---
title: "Analyze 3-day ED revisits"
output: 
  word_document: 
    highlight: kate
---

```{r Import, message=FALSE, warning=FALSE, echo=FALSE, results = FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Clear the environment
rm(list=ls())

# Load all the packages in one shot
x <- c("tidyverse", "aod", "lubridate", "readr", "readxl", "table1", 
       "ggplot2", "MASS", "lmtest", "magrittr")
lapply(x, FUN = function(X) {
    do.call("require", list(X)) 
})

# Import data
r <- read_rds("~/Desktop/ready.RData")
r$triage_delay[is.na(r$triage_delay)] <- 0
adm <- read_excel("admission_data.xlsx")
r2 <- left_join(r, adm, by = 'id_record')
```

### Step 1. Univariate analyses of continuous variables.

Following the outline of *Model-Building Strategies and Methods for Logistic Regression* (Hosmer and Lemeshow, 2013), the first step is to perform univariate analyses for each independent variable, starting with the numeric variables and then the categorical ones. 

```{r Table 1, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
table_one <- r2 %>% dplyr::select(-id_record, -EDrevisit14)

pvalue <- function(x, ...) {
    y <- unlist(x)
    g <- factor(rep(1:length(x), times=sapply(x, length)))
    if (is.numeric(y)) {
        # For numeric variables, perform a standard 2-sample t-test
        p <- t.test(y ~ g)$p.value
    } else {
        # For categorical variables, perform a chi-squared test of independence
        p <- chisq.test(table(y, g))$p.value
    }
    c("", sub("<", "&lt;", format.pval(p, digits=3, eps=0.001)))
}

# Revisits
#table1(~. | EDrevisit30, data=table_one, overall=F, extra.col=list(`P-value`=pvalue))
# 
# table1(~. | EDrevisit3, data=table_one, overall=F, extra.col=list(`P-value`=pvalue))
```
Hosmer and Lemeshow recommend removing variables for which the p-value describing the association with the outcome is less than or equal to 0.25.

```{r Keep predictive variables only, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
r1 <- r %>% dplyr::select(EDrevisit3, zbi_score, pt_sex, pt_age, triage, time_stretcher_hrs, hospital, provenance, Visits365, period, cg_residence)
dependent_variable <- "EDrevisit3"

r1 <- r1 %>%
  mutate(cg_residence = case_when(
    cg_residence == "Home" ~ "home, alone",
    cg_residence == "Home, alone" ~ "home, shared",
    TRUE ~ cg_residence  # Keeps other values unchanged
  ))

r1$cg_residence <- factor(r1$cg_residence, levels = c("home, shared", "home, alone", "Care home"))

# Get the names of predictor variables (all columns except the dependent variable)
predictor_variables <- setdiff(names(r1), dependent_variable)

# Perform glm and extract coefficients for each predictor variable
results <- lapply(predictor_variables, function(predictor) {
  model <- glm(paste(dependent_variable, "~", predictor), data = r1, family = 'binomial')
  coef_values <- coef(model)
  p_values <- coef(summary(model))[, 'Pr(>|z|)']
  
  # Exclude intercept values
  coef_values <- coef_values[-1]
  p_values <- p_values[-1]
  
  result <- data.frame(
    Predictor = predictor,
    Coefficient = coef_values,
    P_Value = p_values
  )
  
  return(result)
})

# Combine the results into a single data frame
results_df <- do.call(rbind, results)

# Print names of variables where p-value is less than or equal to 0.25
significant_variables <- results_df$Predictor[results_df$P_Value <= 0.25]
cat("Variables with p-value less than or equal to 0.25:", paste(significant_variables, collapse = ', '))
```

### Step 2. Fit a model with all covariates identified at Step 1.

Those covariates are pt_sex, triage, triage, triage, time_stretcher_hrs, hospital, hospital, Visits365, period, cg_residence, cg_residence.  

#### Step 2.1. Run an empty model. 

The empty model yields a mean of the distribution = -2.26 meaning there are many more zeroes than ones in the column "EDrevisit7".

```{r Empty model, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
r1 <- r %>% dplyr::select(EDrevisit3, zbi_score, pt_sex, triage, time_stretcher_hrs, hospital, Visits365, period, cg_residence)

empty_model <- glm(EDrevisit3 ~ NULL, data = r1, family = "binomial")
summary(empty_model)
```

```{r Check for multicoliniearity, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
library(car)
colinear_check <- r1 %>%
  dplyr::select_if(is.numeric) %>%
  dplyr::select(-EDrevisit3)

# Find correlations of highly correlated numeric variables
cor_matrix <- cor(colinear_check)

# Use the Variable Inflation Factor (VIF) for all variables
# High VIF values (typically greater than 5 or 10) suggest collinearity.
vif_results <- vif(glm(EDrevisit3 ~ ., data = r1, family = "binomial"))

cor_matrix
vif_results
```

According to VIF estimates and correlations, no variables are problematic. 

#### Step 2.3. Fit a model with all covariates identified at Step 1.

```{r Fit a base model, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
base_model <- glm(EDrevisit3 ~ zbi_score + pt_sex + triage + time_stretcher_hrs + hospital + Visits365 + period + cg_residence, data = r1, family = "binomial")

library(lmtest)
### need to beat the p-value threshold of .05
lrtest(empty_model, base_model)
summary(base_model)
```
## Step 3. Iteratively reduce the model and check for the effects of confounding variables.

```{r Model 2, tidy=TRUE, tidy.opts=list(width.cutoff=50)} 
# remove ZBI score
m2 <- glm(EDrevisit3 ~ pt_sex + triage + time_stretcher_hrs + hospital + Visits365 + period + cg_residence, data = r1, family = "binomial")

# Likelihood Ratio Test
lrtest(base_model, m2)
summary(m2)

m1_summary <- as.data.frame(broom::tidy(base_model))
m2_summary <- as.data.frame(broom::tidy(m2))

m1m2 <- dplyr::left_join(
  m1_summary,
  m2_summary,
  by = 'term',
  copy = FALSE,
  suffix = c(".m1", ".m2")
)

m1m2 <- m1m2 %>%
  dplyr::select(term, estimate.m1, estimate.m2) %>%
  dplyr::mutate(
    change = estimate.m1 - estimate.m2,
    twenty_percent = abs(estimate.m1) * 0.2,
    beta_changed = if_else(abs(change) >= twenty_percent, TRUE, FALSE)
  )

print(m1m2)
```

```{r Model 3, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
# Next, remove hospital
m3 <- glm(EDrevisit3 ~ pt_sex + triage + time_stretcher_hrs + Visits365 + period + cg_residence, data = r1, family = "binomial")

summary(m3)

# Likelihood Ratio Test
lrtest(m2, m3)

m2_summary <- as.data.frame(broom::tidy(m2))
m3_summary <- as.data.frame(broom::tidy(m3))

m1m2 <- dplyr::left_join(
  m2_summary,
  m3_summary,
  by = 'term',
  copy = FALSE,
  suffix = c(".m2", ".m3")
)

m1m2 <- m1m2 %>%
  dplyr::select(term, estimate.m2, estimate.m3) %>%
  dplyr::mutate(
    change = estimate.m2 - estimate.m3,
    twenty_percent = abs(estimate.m2) * 0.2,
    beta_changed = if_else(abs(change) >= twenty_percent, TRUE, FALSE)
  )
print(m1m2)
```

```{r Model 4, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m4 <- glm(EDrevisit3 ~ pt_sex + triage + time_stretcher_hrs + Visits365 + cg_residence, data = r1, family = "binomial")
summary(m4)
lrtest(m3, m4)

m4_summary <- as.data.frame(broom::tidy(m4))
m3_summary <- as.data.frame(broom::tidy(m3))

m1m2 <- dplyr::left_join(
  m3_summary,
  m4_summary,
  by = 'term',
  copy = FALSE,
  suffix = c(".m3", ".m4")
)

m1m2 <- m1m2 %>%
  dplyr::select(term, estimate.m3, estimate.m4) %>%
  dplyr::mutate(
    change = estimate.m3 - estimate.m4,
    twenty_percent = abs(estimate.m3) * 0.2,
    beta_changed = if_else(abs(change) >= twenty_percent, TRUE, FALSE)
  )
print(m1m2)
```

```{r Model 5, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m5 <- glm(EDrevisit3 ~ triage + time_stretcher_hrs + Visits365 + cg_residence, data = r1, family = "binomial")
summary(m5)
lrtest(m4, m5)

m4_summary <- as.data.frame(broom::tidy(m4))
m5_summary <- as.data.frame(broom::tidy(m5))

m1m2 <- dplyr::left_join(
  m4_summary,
  m5_summary,
  by = 'term',
  copy = FALSE,
  suffix = c(".m4", ".m5")
)

m1m2 <- m1m2 %>%
  dplyr::select(term, estimate.m4, estimate.m5) %>%
  dplyr::mutate(
    change = estimate.m4 - estimate.m5,
    twenty_percent = abs(estimate.m4) * 0.2,
    beta_changed = if_else(abs(change) >= twenty_percent, TRUE, FALSE)
  )
print(m1m2)
```
```{r Compare models, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
models <- list(m2, m3, m4, m5)
summaries <- lapply(models, summary)
summaries 
# m8 had the best AIC
# Likelihood Ratio Tests
lrtest(m2, m5)
lrtest(base_model, m5) 
lrtest(empty_model, m5)
```

Model 6 is better than both the base model and the empty model. 

## Step 4. Add variables back into the model ##

Model M5 appears to be the most reduced model without experiencing moderation by removing variables. 

Next, add each variable not selected in Step 1 to the model obtained at the conclusion of cycling through Step 2 and Step 3, one at a time, and check its significance either by the Wald statistic p-value or the partial likelihood ratio test, if it is a categorical variable with more than two levels.

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
### Variables we did not select

used <- c('zbi_score', 'pt_sex', 'triage', 'time_stretcher_hrs', 'hospital', 'Visits365', 'period', 'cg_residence')

#not used
vars <- c("triage", "triage_delay", "provenance", "soutien_social", "charlson_score_adj", "cg_sex", "med_fam", "rv_med_fam", "transport", "pt_education", "cg_education", "cg_pt_relation", "pt_revenue", "cg_revenue", "pt_residence")      

ma <- glm(EDrevisit3 ~ triage + time_stretcher_hrs + Visits365 + cg_residence, data = r1, family = "binomial")

model_list <- list()

### Run the models one by one, adding one of the vars as a predictor each time
for (i in seq_along(vars)) {
  formula <- as.formula(paste("EDrevisit3 ~ triage + time_stretcher_hrs + Visits365 + cg_residence +", vars[i]))
  model <- glm(formula, data = r, family = "binomial")
  assign(paste0("ma", i), model)
}

### Print the model summaries with the Wald Tests
for (i in seq_along(vars)) {
  model_name <- paste0("ma", i)
  model_summary <- summary(get(model_name))
  print(paste("Summary for", model_name))
  print(model_summary)
}

### Likelihood Ratio Tests
for (i in seq_along(vars)) {
  model_name <- paste0("ma", i)
  model_summary <- lrtest(m5, get(model_name))
  print(paste("LRT Result for", model_name))
  print(model_summary)
}
```

None of these new added variables are statistically significant. None of these new variables add new information to the model. 

## Step 5. Check Assumptions of linearity ##

For each continuous variable in this model we must check the assumption that the logit increases/decreases linearly as a function of the covariate.

There are four methods to address this assumption: (i) smoothed scatter plots, (ii) design variables (stratify into quartiles and see how the coefficients change), (iii) fractional polynomials and (iv) spline functions.

Judging by the scatterplots, the distributions do not seem non-linear, so I think we can treat the ZBI and Visits over the previous year as linear in the logit. 

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int <- glm(EDrevisit3 ~ triage + time_stretcher_hrs + Visits365 + cg_residence, data = r1, family = "binomial")
summary(m_int)
```

```{r Assumption of linearity, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
### Scatterplots
# Run logistic regression model
logit_model <- m_int

# Save logit scores as a new variable in the dataset
r1$logit_scores <- predict(logit_model, type = "link")

# Create scatterplots for each continuous IV against logit scores
par(mfrow = c(2, ceiling(length(c('Visits365', 'time_stretcher_hrs', 'zbi_score'))/2)), mar = c(3, 3, 2, 1))

for (iv in c('Visits365', 'time_stretcher_hrs', 'zbi_score')) {
  plot(r1[[iv]], r1$logit_scores, main = paste("Scatterplot of", iv, "against Logit Scores"), xlab = iv, ylab = "Logit Scores")
}
```
## Step 6. Look for interactions ##

The next step in the purposeful selection procedure is to explore possible interactions among the main effects. Each pair of main effects should represent a plausible interaction. Hence, we fit models that individually added possible interactions to the main effects model.

An interaction between two variables implies that the effect of each variable is not constant over levels of the other variable.

In the textbook, they specify this threshold as .10 when looking for interactions, and then as .05 when evaluating them.  

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int <- glm(EDrevisit3 ~ triage + time_stretcher_hrs + Visits365 + cg_residence, data = r1, family = "binomial")
summary(m_int)
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int2 <- glm(EDrevisit3 ~ time_stretcher_hrs*triage  + Visits365*triage  + cg_residence*triage, data = r1, family = "binomial")
summary(m_int2)
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int3 <- glm(EDrevisit3 ~ triage*time_stretcher_hrs + Visits365*time_stretcher_hrs + cg_residence*time_stretcher_hrs, data = r1, family = "binomial")
summary(m_int3)
```

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int4 <- glm(EDrevisit3 ~ triage*Visits365 + time_stretcher_hrs*Visits365 + cg_residence*Visits365, data = r1, family = "binomial")
summary(m_int4)
# triage * Visits365
```
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int5 <- glm(EDrevisit3 ~ triage*cg_residence + time_stretcher_hrs*cg_residence + Visits365*cg_residence, data = r1, family = "binomial")
summary(m_int5)
```

No evidence of any interactions. 

## Step 7. Assess Goodness of Fit ##

In the Hosmer-Lemeshow model, a large value of Chi-squared (with small p-value \< 0.05) indicates poor fit and small Chi-squared values (with larger p-value closer to 1) indicate a good logistic regression model fit.

The g in the formula represents the groups, such that g = 10 means we are splitting the data into 10 groups based on their predicted probabilities and then, within groups, comparing the observed and expected proportions.

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
m_int <- glm(EDrevisit3 ~ triage + time_stretcher_hrs + zbi_score + Visits365 + cg_residence, data = r1, family = "binomial")
summary(m_int)
```

```{r Goodness of fit, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
library(ResourceSelection)
# Check the model fit across all the individuals
fit <- m_int$fitted
hist(fit)
summary(m_int)

### Method 1: Do it by hand!
# Calculate the residuals
# Sum of squares of these residuals follows a chi-square with 1406 df

r <- (r1$EDrevisit3-fit)/(sqrt(fit*(1-fit)))
sum(r^2)
1-pchisq(sum(r^2), df=1401) # not significant

### Method 2 for Goodness of Fit: 
hl_gof <- hoslem.test(r1$EDrevisit3, fitted(m_int), g = 10)
hl_gof
```
So model M5 is the final adjusted model predicting 3 day revisits. 

```{r C-Statistic and ROC curve, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
library(DescTools)
library(pROC)
Cstat(m_int)

predictions <- predict(m_int, type = "response")
roc(r1$EDrevisit3, predictions)

# Roc Curve

roc3 <- ggroc(roc(r1$EDrevisit3, predictions), colour = "darkorange1") +
  theme_minimal() + 
  ggtitle("") + 
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1), color="gray", linetype="dashed")

# C statistics
survival::concordance(m_int)
```
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=50)}
save(roc3, file = "~/Desktop/roc3.RData")
```
